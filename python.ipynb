{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostRegressor\n",
    "from tpot import TPOTRegressor\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder,StandardScaler,OrdinalEncoder,LabelEncoder\n",
    "from xgboost import XGBRegressor\n",
    "from tensorflow.keras.layers import Normalization\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.model_selection import train_test_split,cross_val_score,GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv(\"/kaggle/input/intra-aims-ml-challenge/train_set.csv\")\n",
    "test1=pd.read_csv(\"/kaggle/input/intra-aims-ml-challenge/test_set.csv\")\n",
    "test=pd.read_csv(\"/kaggle/input/intra-aims-ml-challenge/test_set.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.describe(include='object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=train[['Product_Code','Product_Weight','Fat_Category','Visibility_Score','Category_Type','Retail_Price','Store_Code','Year_Opened','Store_Size','Location_Class','Store_Category']]\n",
    "Y=train.Total_Sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['Year_Opened'] = 2024 - X['Year_Opened']\n",
    "\n",
    "cat_cols = ['Product_Code','Fat_Category','Category_Type','Store_Code','Store_Size','Location_Class', 'Store_Category']  \n",
    "num_cols = ['Product_Weight', 'Visibility_Score', 'Retail_Price', 'Year_Opened']  # Example numerical columns\n",
    "\n",
    "\n",
    "cat_tf1 = Pipeline(steps=[\n",
    "     \n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore')),\n",
    "    ('imputer', SimpleImputer(strategy='mean')) \n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "scaler = RobustScaler()\n",
    "\n",
    "\n",
    "X_scaled = scaler.fit_transform(X[['Visibility_Score']])\n",
    "\n",
    "print(X_scaled)\n",
    "\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "X['Fat_Category'] = label_encoder.fit_transform(X['Fat_Category'])\n",
    "X['Store_Size'] = label_encoder.fit_transform(X['Store_Size'])\n",
    "\n",
    "\n",
    "freq_encoding = X['Product_Code'].value_counts().to_dict()\n",
    "X['Product_Code'] = X['Product_Code'].map(freq_encoding)\n",
    "\n",
    "X['Visibility_Score'].fillna(X['Visibility_Score'].median(), inplace=True)\n",
    "\n",
    "\n",
    "X['Product_Weight'] = X.groupby('Category_Type')['Product_Weight'].transform(lambda x: x.fillna(x.mean()))\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('onehot', cat_tf1, cat_cols),  \n",
    "        ('scaler', scaler, num_cols)  \n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "X_train, X_valid, Y_train, Y_valid = train_test_split(X, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CatBoostRegressor(\n",
    "    iterations=2400, \n",
    "    l2_leaf_reg=5,\n",
    "    learning_rate=0.0035,            \n",
    "    depth=5,\n",
    "    early_stopping_rounds=50,                      \n",
    "    loss_function=\"RMSE\",         \n",
    "    verbose=70                  \n",
    ")\n",
    "\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),  \n",
    "    ('model', model)   ])             \n",
    "\n",
    "pipeline.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred = pipeline.predict(X_valid)\n",
    "\n",
    "print(\"Mean Squared Error = \", mse(Y_valid, Y_pred))\n",
    "print(\"Mean Absolute Error = \", mae(Y_valid, Y_pred), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[\"Year_Opened\"]=2024-test[\"Year_Opened\"]\n",
    "\n",
    "test_pred=pipeline.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output=pd.DataFrame({'Id':test1.Id,'Total_Sales':test_pred})\n",
    "output.to_csv('AnugyaAIMSSubmission.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
